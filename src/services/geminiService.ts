/**
 * Gemini AI Service - AI Tutor cho LMS
 * H·ªó tr·ª£ h·ªçc sinh v√† Gi√°o vi√™n
 */
import { GoogleGenAI } from "@google/genai";
import { TutorContext, TutorResponse, Question, Theory } from '../types';

// API Key t·ª´ environment
const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

// Track hint levels per question
const hintLevels: Map<string, number> = new Map();

/**
 * L·∫•y hint level hi·ªán t·∫°i cho m·ªôt c√¢u h·ªèi
 */
export const getHintLevel = (questionId: string): number => {
  return hintLevels.get(questionId) || 0;
};

/**
 * TƒÉng hint level cho m·ªôt c√¢u h·ªèi
 */
export const incrementHintLevel = (questionId: string): number => {
  const current = getHintLevel(questionId);
  const newLevel = Math.min(current + 1, 3);
  hintLevels.set(questionId, newLevel);
  return newLevel;
};

/**
 * Reset hint level cho m·ªôt c√¢u h·ªèi
 */
export const resetHintLevel = (questionId: string): void => {
  hintLevels.delete(questionId);
};

/**
 * Reset t·∫•t c·∫£ hint levels
 */
export const resetAllHints = (): void => {
  hintLevels.clear();
};

/**
 * Helper: Clean and Parse JSON safely
 */
function safeJSONParse(text: string): any {
  if (!text) return {};
  
  // 1. Remove Markdown code blocks
  let cleanText = text.replace(/```json/g, '').replace(/```/g, '').trim();
  
  try {
    return JSON.parse(cleanText);
  } catch (error) {
    console.warn('First JSON parse attempt failed, trying to sanitize backslashes...', error);
    // N·∫øu l·ªói v·∫´n x·∫£y ra, tr·∫£ v·ªÅ null ƒë·ªÉ UI x·ª≠ l√Ω (hi·ªÉn th·ªã l·ªói ho·∫∑c th·ª≠ l·∫°i)
    return null;
  }
}

/**
 * Helper: T√°ch ·∫£nh base64 ra kh·ªèi markdown ƒë·ªÉ gi·∫£m token
 */
function extractImages(markdown: string): { cleanText: string; imageMap: Map<string, string> } {
  const imageMap = new Map<string, string>();
  let counter = 0;
  
  // Regex b·∫Øt pattern ![alt](data:image...)
  // Group 1: alt text, Group 2: data uri
  const cleanText = markdown.replace(/!\[(.*?)\]\((data:image\/[^)]+)\)/g, (match, alt, dataUri) => {
    const placeholder = `{{__IMG_${counter}__}}`;
    imageMap.set(placeholder, match); // L∆∞u l·∫°i to√†n b·ªô tag ·∫£nh g·ªëc
    counter++;
    return placeholder; // Thay th·∫ø b·∫±ng placeholder trong text g·ª≠i ƒëi
  });

  return { cleanText, imageMap };
}

/**
 * Helper: Kh√¥i ph·ª•c l·∫°i ·∫£nh t·ª´ placeholder
 */
function restoreImages(text: string, imageMap: Map<string, string>): string {
  let restoredText = text;
  imageMap.forEach((originalImageTag, placeholder) => {
    // Thay th·∫ø t·∫•t c·∫£ c√°c l·∫ßn xu·∫•t hi·ªán c·ªßa placeholder (ƒë·ªÅ ph√≤ng model l·∫∑p l·∫°i)
    restoredText = restoredText.split(placeholder).join(originalImageTag);
  });
  return restoredText;
}

/**
 * H·ªèi AI Tutor
 */
export const askAITutor = async (
  userMessage: string,
  context?: TutorContext
): Promise<TutorResponse> => {
  // Get current hint level
  const hintLevel = context?.questionId ? getHintLevel(context.questionId) : 0;
  
  // Build system prompt based on hint level
  const systemPrompt = buildSystemPrompt(hintLevel, context);
  
  try {
    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: `C√¢u h·ªèi c·ªßa h·ªçc sinh: ${userMessage}`,
      config: {
        systemInstruction: systemPrompt,
        temperature: 0.7,
        topK: 40,
        topP: 0.95,
      },
    });
    
    const message = response.text;
    
    if (message) {
      // Increment hint level if this was a hint request
      if (context?.questionId && userMessage.toLowerCase().includes('g·ª£i √Ω')) {
        incrementHintLevel(context.questionId);
      }
      
      return {
        message,
        hintLevel,
        isFullSolution: hintLevel >= 3
      };
    }
    
    return getFallbackResponse(hintLevel, context);
    
  } catch (error) {
    console.error('AI Tutor error:', error);
    return getFallbackResponse(hintLevel, context);
  }
};

/**
 * T·∫°o c√¢u h·ªèi m·ªõi t·ª´ AI (Gi√°o vi√™n)
 */
export const generateQuestionFromAI = async (
  grade: number,
  topic: string,
  level: string, // Nh·∫≠n bi·∫øt, Th√¥ng hi·ªÉu...
  type: 'Tr·∫Øc nghi·ªám' | 'ƒê√∫ng/Sai' | 'Tr·∫£ l·ªùi ng·∫Øn',
  sourceText?: string // Ngu·ªìn vƒÉn b·∫£n (n·∫øu c√≥ OCR)
): Promise<Partial<Question> | null> => {
  try {
    let prompt = `T·∫°o m·ªôt c√¢u h·ªèi to√°n h·ªçc L·ªõp ${grade}, Ch·ªß ƒë·ªÅ "${topic}", M·ª©c ƒë·ªô "${level}", D·∫°ng c√¢u h·ªèi "${type}".\n`;
    
    if (sourceText) {
      // N·∫øu c√≥ sourceText (t·ª´ OCR), h√£y t√°ch ·∫£nh ra ƒë·ªÉ tr√°nh l·ªói token qu√° l·ªõn khi generate
      const { cleanText } = extractImages(sourceText);
      prompt += `\n[QUAN TR·ªåNG] D·ª±a v√†o n·ªôi dung vƒÉn b·∫£n sau ƒë·ªÉ t·∫°o c√¢u h·ªèi (c√≥ th·ªÉ ch·ªânh s·ª≠a s·ªë li·ªáu m·ªôt ch√∫t ƒë·ªÉ t·∫°o bi·∫øn th·ªÉ):\n"""${cleanText}"""\n`;
    }

    prompt += `
    \n[Y√äU C·∫¶U ƒê·ªäNH D·∫†NG JSON & LATEX - R·∫§T QUAN TR·ªåNG]:
    1. Output ph·∫£i l√† m·ªôt JSON Object h·ª£p l·ªá (kh√¥ng d√πng Markdown code block).
    2. T·∫§T C·∫¢ c√°c bi·ªÉu th·ª©c to√°n h·ªçc, bi·∫øn s·ªë, ph∆∞∆°ng tr√¨nh ph·∫£i vi·∫øt d∆∞·ªõi d·∫°ng LaTeX v√† ƒë·∫∑t trong d·∫•u $.
    3. QUAN TR·ªåNG: Trong chu·ªói JSON, k√Ω t·ª± backslash (\\) c·ªßa LaTeX ph·∫£i ƒë∆∞·ª£c ESCAPE (vi·∫øt th√†nh \\\\).
       - SAI: "$\\frac{1}{2}$" (L·ªói JSON v√¨ \\f l√† form feed ho·∫∑c \\ kh√¥ng h·ª£p l·ªá)
       - ƒê√öNG: "$\\\\frac{1}{2}$" (JSON h·ª£p l·ªá)
       - SAI: "$\\alpha$"
       - ƒê√öNG: "$\\\\alpha$"
       - SAI: "D = R \\ {1}"
       - ƒê√öNG: "D = R \\\\setminus {1}"
    4. H√£y ki·ªÉm tra k·ªπ c√∫ ph√°p JSON tr∆∞·ªõc khi tr·∫£ v·ªÅ.
    `;

    if (type === 'Tr·∫Øc nghi·ªám') {
      prompt += `Y√™u c·∫ßu output JSON format:
      {
        "question_text": "N·ªôi dung c√¢u h·ªèi (LaTeX $\\\\dots$)",
        "option_A": "ƒê√°p √°n A (LaTeX $\\\\dots$)",
        "option_B": "ƒê√°p √°n B (LaTeX $\\\\dots$)",
        "option_C": "ƒê√°p √°n C (LaTeX $\\\\dots$)",
        "option_D": "ƒê√°p √°n D (LaTeX $\\\\dots$)",
        "answer_key": "A",
        "solution": "L·ªùi gi·∫£i chi ti·∫øt (LaTeX $\\\\dots$)"
      }`;
    } else if (type === 'ƒê√∫ng/Sai') {
      prompt += `Y√™u c·∫ßu output JSON format:
      {
        "question_text": "N·ªôi dung c√¢u h·ªèi ch√≠nh (LaTeX $\\\\dots$)",
        "option_A": "M·ªánh ƒë·ªÅ a (LaTeX $\\\\dots$)",
        "option_B": "M·ªánh ƒë·ªÅ b (LaTeX $\\\\dots$)",
        "option_C": "M·ªánh ƒë·ªÅ c (LaTeX $\\\\dots$)",
        "option_D": "M·ªánh ƒë·ªÅ d (LaTeX $\\\\dots$)",
        "answer_key": "ƒê-S-ƒê-S",
        "solution": "Gi·∫£i th√≠ch t·ª´ng m·ªánh ƒë·ªÅ (LaTeX $\\\\dots$)"
      }`;
    } else {
      prompt += `Y√™u c·∫ßu output JSON format:
      {
        "question_text": "N·ªôi dung c√¢u h·ªèi (LaTeX $\\\\dots$)",
        "answer_key": "Gi√° tr·ªã s·ªë ho·∫∑c bi·ªÉu th·ª©c ng·∫Øn g·ªçn",
        "solution": "L·ªùi gi·∫£i chi ti·∫øt (LaTeX $\\\\dots$)"
      }`;
    }

    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: prompt,
      config: {
        responseMimeType: 'application/json',
        temperature: 0.7 // Gi·∫£m nhi·ªát ƒë·ªô ƒë·ªÉ model tu√¢n th·ªß format t·ªët h∆°n
      }
    });

    const json = safeJSONParse(response.text || '{}');
    if (!json) return null;

    return {
      ...json,
      grade,
      topic,
      level,
      question_type: type
    };

  } catch (error) {
    console.error('Gen Question Error:', error);
    return null;
  }
};

/**
 * Th·ª±c hi·ªán OCR (Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ file)
 */
export const performOCR = async (base64Data: string, mimeType: string): Promise<string | null> => {
  try {
    const prompt = `H√£y ƒë√≥ng vai tr√≤ l√† m·ªôt c√¥ng c·ª• OCR To√°n h·ªçc chuy√™n nghi·ªáp. 
    Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr√≠ch xu·∫•t to√†n b·ªô n·ªôi dung vƒÉn b·∫£n v√† c√¥ng th·ª©c to√°n h·ªçc t·ª´ h√¨nh ·∫£nh/file PDF n√†y.
    
    Y√™u c·∫ßu:
    1. Gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng c√¥ng th·ª©c to√°n h·ªçc, chuy·ªÉn ƒë·ªïi ch√∫ng sang ƒë·ªãnh d·∫°ng LaTeX chu·∫©n (ƒë·∫∑t trong d·∫•u $...$ ho·∫∑c $$...$$).
    2. N·∫øu c√≥ nhi·ªÅu c√¢u h·ªèi, h√£y tr√≠ch xu·∫•t t·∫•t c·∫£.
    3. Kh√¥ng th√™m l·ªùi b√¨nh lu·∫≠n, ch·ªâ tr·∫£ v·ªÅ n·ªôi dung th√¥ ƒë√£ tr√≠ch xu·∫•t.
    `;

    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: {
        parts: [
          {
            inlineData: {
              mimeType: mimeType,
              data: base64Data
            }
          },
          { text: prompt }
        ]
      }
    });

    return response.text || null;
  } catch (error) {
    console.error('OCR Error:', error);
    return null;
  }
};

/**
 * üÜï Correct OCR Text using Gemini (with Streaming)
 * Use for the new PDF Exam features
 * Updated: Handles large images by placeholder extraction
 */
export const correctTextStream = async (text: string, onUpdate: (chunk: string) => void): Promise<string> => {
  // 1. T√°ch ·∫£nh ƒë·ªÉ gi·∫£m token v√† tr√°nh l·ªói
  const { cleanText, imageMap } = extractImages(text);

  const prompt = `
    B·∫°n l√† chuy√™n gia bi√™n t·∫≠p ti·∫øng Vi·ªát. Nhi·ªám v·ª• c·ªßa b·∫°n l√† s·ª≠a l·ªói ch√≠nh t·∫£ v√† ng·ªØ ph√°p cho vƒÉn b·∫£n OCR sau ƒë√¢y.
    
    Y√™u c·∫ßu QUAN TR·ªåNG:
    1. GI·ªÆ NGUY√äN c·∫•u tr√∫c Markdown (ti√™u ƒë·ªÅ, danh s√°ch, b·∫£ng bi·ªÉu, in ƒë·∫≠m, in nghi√™ng).
    2. GI·ªÆ NGUY√äN c√°c placeholder h√¨nh ·∫£nh d·∫°ng {{__IMG_x__}}. TUY·ªÜT ƒê·ªêI KH√îNG XO√Å HO·∫∂C S·ª¨A CH√öNG.
    3. GI·ªÆ NGUY√äN c√°c c√¥ng th·ª©c LaTeX (d·∫°ng $...$ ho·∫∑c $$...$$).
    4. Ch·ªâ s·ª≠a c√°c t·ª´ b·ªã sai ch√≠nh t·∫£, d·∫•u c√¢u sai, ho·∫∑c ng·ªØ ph√°p l·ªßng c·ªßng do qu√° tr√¨nh OCR.
    5. KH√îNG th√™m l·ªùi d·∫´n, KH√îNG gi·∫£i th√≠ch. Ch·ªâ tr·∫£ v·ªÅ vƒÉn b·∫£n ƒë√£ s·ª≠a.

    VƒÉn b·∫£n g·ªëc:
    """
    ${cleanText}
    """
  `;

  try {
    const result = await ai.models.generateContentStream({
      model: 'gemini-3-flash-preview',
      contents: prompt,
      config: {
        temperature: 0.1, // Low temp for consistency
        maxOutputTokens: 65536 // Increased to 65536 to handle large documents
      }
    });

    let fullText = '';
    for await (const chunk of result) {
      const chunkText = chunk.text;
      if (chunkText) {
        fullText += chunkText;
        onUpdate(chunkText); // Stream text (s·∫Ω ch·ª©a placeholder)
      }
    }
    
    // 2. Kh√¥i ph·ª•c ·∫£nh v√†o k·∫øt qu·∫£ cu·ªëi c√πng
    const finalText = restoreImages(fullText, imageMap);
    return finalText;
  } catch (error) {
    console.error("Error correcting text:", error);
    throw error;
  }
};

/**
 * üÜï Parse Full Exam Markdown into Questions
 */
export const parseQuestionsFromMarkdown = async (markdownText: string, grade: number, topic: string): Promise<Partial<Question>[]> => {
  // T√°ch ·∫£nh ra kh·ªèi markdown tr∆∞·ªõc khi g·ª≠i parse ƒë·ªÉ tr√°nh token limit
  const { cleanText, imageMap } = extractImages(markdownText);

  const prompt = `
    B·∫°n l√† h·ªá th·ªëng tr√≠ch xu·∫•t ƒë·ªÅ thi To√°n th√¥ng minh.
    Nhi·ªám v·ª•: Ph√¢n t√≠ch vƒÉn b·∫£n Markdown b√™n d∆∞·ªõi v√† tr√≠ch xu·∫•t TO√ÄN B·ªò danh s√°ch c√¢u h·ªèi th√†nh m·∫£ng JSON.
    VƒÉn b·∫£n c√≥ th·ªÉ ch·ª©a nhi·ªÅu c√¢u (VD: C√¢u 1 ƒë·∫øn C√¢u 22). H√£y c·ªë g·∫Øng kh√¥ng b·ªè s√≥t c√¢u n√†o.

    [QUY T·∫ÆC PH√ÇN LO·∫†I C√ÇU H·ªéI]:
    H√£y xem x√©t c√°c l·ª±a ch·ªçn ƒë√°p √°n c·ªßa t·ª´ng c√¢u h·ªèi ƒë·ªÉ quy·∫øt ƒë·ªãnh 'question_type':

    1. **Tr·∫Øc nghi·ªám** (Multiple Choice):
       - D·∫•u hi·ªáu: C√≥ c√°c l·ª±a ch·ªçn b·∫Øt ƒë·∫ßu b·∫±ng ch·ªØ c√°i IN HOA nh∆∞ A., B., C., D. (ho·∫∑c A:, B:, C:, D:).
       - H√†nh ƒë·ªông:
         + type = "Tr·∫Øc nghi·ªám"
         + ƒê∆∞a n·ªôi dung sau A. v√†o field "option_A"
         + ƒê∆∞a n·ªôi dung sau B. v√†o field "option_B" (t∆∞∆°ng t·ª± C, D)

    2. **ƒê√∫ng/Sai** (True/False):
       - D·∫•u hi·ªáu: C√≥ c√°c √Ω nh·ªè b·∫Øt ƒë·∫ßu b·∫±ng ch·ªØ c√°i th∆∞·ªùng a), b), c), d) (ho·∫∑c a., b., c., d.).
       - H√†nh ƒë·ªông:
         + type = "ƒê√∫ng/Sai"
         + ƒê∆∞a n·ªôi dung √Ω a) v√†o field "option_A"
         + ƒê∆∞a n·ªôi dung √Ω b) v√†o field "option_B" (t∆∞∆°ng t·ª± c, d)

    3. **Tr·∫£ l·ªùi ng·∫Øn** (Short Answer):
       - D·∫•u hi·ªáu: Kh√¥ng c√≥ c√°c l·ª±a ch·ªçn A/B/C/D hay a/b/c/d. Th∆∞·ªùng y√™u c·∫ßu "T√≠nh...", "T√¨m...", "Cho bi·∫øt...".
       - H√†nh ƒë·ªông:
         + type = "Tr·∫£ l·ªùi ng·∫Øn"
         + C√°c field option_A...D ƒë·ªÉ tr·ªëng ho·∫∑c null.

    [Y√äU C·∫¶U OUTPUT JSON]:
    - Output l√† m·ªôt JSON Array: [ {...}, {...} ]
    - C√°c tr∆∞·ªùng b·∫Øt bu·ªôc: "question_type", "question_text", "option_A", "option_B", "option_C", "option_D".
    - "answer_key": N·∫øu ƒë·ªÅ c√≥ ƒë√°p √°n, h√£y ƒëi·ªÅn (VD: "A", "ƒê-S-S-ƒê", ho·∫∑c "15"). N·∫øu kh√¥ng, ƒë·ªÉ tr·ªëng.
    - "solution": L·ªùi gi·∫£i chi ti·∫øt (n·∫øu c√≥).
    - "image_id": N·∫øu c√¢u h·ªèi ch·ª©a h√¨nh ·∫£nh ({{__IMG_x__}} ho·∫∑c ![...]), h√£y tr√≠ch xu·∫•t placeholder ƒë√≥ v√†o ƒë√¢y.
    - LaTeX ph·∫£i ƒë∆∞·ª£c double-escape (\\\\frac instead of \\frac).

    [VƒÇN B·∫¢N ƒê·ªÄ THI]:
    """
    ${cleanText}
    """
  `;

  try {
    const response = await ai.models.generateContent({
        model: 'gemini-3-flash-preview',
        contents: prompt,
        config: {
            responseMimeType: 'application/json',
            temperature: 0.1,
            maxOutputTokens: 65536 // Increased to 65536 to ensure full JSON extraction
        }
    });
    
    const parsed = safeJSONParse(response.text || '[]');
    if (!Array.isArray(parsed)) return [];
    
    // Restore images inside image_id if necessary
    return parsed.map((q: any) => {
        let fullImageTag = q.image_id;
        if (q.image_id && imageMap.has(q.image_id)) {
            fullImageTag = imageMap.get(q.image_id);
        }

        return {
            ...q,
            image_id: fullImageTag,
            grade,
            topic,
            level: 'Th√¥ng hi·ªÉu',
            quiz_level: 1
        };
    });
  } catch (error) {
    console.error("Error parsing questions:", error);
    return [];
  }
};

/**
 * T·∫°o L√Ω thuy·∫øt t·ª´ AI (Gi√°o vi√™n)
 */
export const generateTheoryFromAI = async (
  grade: number,
  topic: string,
  level: number
): Promise<Partial<Theory> | null> => {
  try {
    const prompt = `So·∫°n t√†i li·ªáu l√Ω thuy·∫øt to√°n h·ªçc ng·∫Øn g·ªçn.
    L·ªõp: ${grade}
    Ch·ªß ƒë·ªÅ: ${topic}
    Level: ${level} (C√†ng cao c√†ng n√¢ng cao)

    [Y√äU C·∫¶U ƒê·ªäNH D·∫†NG JSON & LATEX]:
    1. Output l√† JSON Object h·ª£p l·ªá.
    2. M·ªçi c√¥ng th·ª©c to√°n ph·∫£i vi·∫øt b·∫±ng LaTeX trong d·∫•u $...$ ho·∫∑c $$...$$.
    3. ESCAPE d·∫•u backslash: D√πng \\\\frac thay v√¨ \\frac trong chu·ªói JSON.

    Y√™u c·∫ßu output JSON format:
    {
      "title": "Ti√™u ƒë·ªÅ b√†i h·ªçc (Ng·∫Øn g·ªçn)",
      "content": "N·ªôi dung l√Ω thuy·∫øt ch√≠nh. D√πng LaTeX (\\\\frac, \\\\alpha...) cho c√¥ng th·ª©c.",
      "examples": "1-2 V√≠ d·ª• minh h·ªça. D√πng LaTeX.",
      "tips": "M·∫πo ghi nh·ªõ."
    }`;

    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: prompt,
      config: {
        responseMimeType: 'application/json',
        temperature: 0.7
      }
    });

    const json = safeJSONParse(response.text || '{}');
    if (!json) return null;

    return {
      ...json,
      grade,
      topic,
      level
    };

  } catch (error) {
    console.error('Gen Theory Error:', error);
    return null;
  }
};

/**
 * Build system prompt based on hint level
 */
function buildSystemPrompt(hintLevel: number, context?: TutorContext): string {
  const basePrompt = `B·∫°n l√† "Tr·ª£ L√Ω Th·∫ßy Ph√∫c", m·ªôt gia s∆∞ To√°n h·ªçc th√¢n thi·ªán v√† ki√™n nh·∫´n.
B·∫°n ƒëang gi√∫p h·ªçc sinh c·∫•p 3 ·ªü Vi·ªát Nam.
H√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, s·ª≠ d·ª•ng c√¥ng th·ª©c LaTeX khi c·∫ßn (ƒë·∫∑t trong d·∫•u $).
`;

  let levelPrompt = '';
  
  switch (hintLevel) {
    case 0:
      levelPrompt = `
üîπ ƒê√ÇY L√Ä G·ª¢I √ù C·∫§P 0 (T·ªïng quan):
- Ch·ªâ ƒë∆∞a ra h∆∞·ªõng ti·∫øp c·∫≠n chung
- KH√îNG gi·∫£i b√†i ho·∫∑c ƒë∆∞a ra c√°c b∆∞·ªõc c·ª• th·ªÉ
- G·ª£i √Ω v·ªÅ lo·∫°i b√†i to√°n v√† ph∆∞∆°ng ph√°p n√™n d√πng
- Khuy·∫øn kh√≠ch h·ªçc sinh t·ª± suy nghƒ©
- V√≠ d·ª•: "ƒê√¢y l√† b√†i v·ªÅ ƒë·∫°o h√†m, em th·ª≠ nh·ªõ l·∫°i c√¥ng th·ª©c ƒë·∫°o h√†m c·ªßa h√†m s·ªë m≈© nh√©!"
`;
      break;
      
    case 1:
      levelPrompt = `
üî∏ ƒê√ÇY L√Ä G·ª¢I √ù C·∫§P 1 (B∆∞·ªõc ƒë·∫ßu):
- ƒê∆∞a ra b∆∞·ªõc ƒë·∫ßu ti√™n c·∫ßn l√†m
- Nh·∫Øc l·∫°i c√¥ng th·ª©c/ƒë·ªãnh l√Ω li√™n quan
- V·∫´n ƒë·ªÉ h·ªçc sinh t·ª± th·ª±c hi·ªán c√°c b∆∞·ªõc ti·∫øp theo
- V√≠ d·ª•: "B∆∞·ªõc 1 l√† t√≠nh ƒë·∫°o h√†m. C√¥ng th·ª©c: $(e^x)' = e^x$. Em th·ª≠ t√≠nh ƒë·∫°o h√†m c·ªßa h√†m s·ªë n√†y xem."
`;
      break;
      
    case 2:
      levelPrompt = `
üî∂ ƒê√ÇY L√Ä G·ª¢I √ù C·∫§P 2 (Chi ti·∫øt):
- H∆∞·ªõng d·∫´n t·ª´ng b∆∞·ªõc nh∆∞ng kh√¥ng ƒë∆∞a k·∫øt qu·∫£ cu·ªëi
- Gi√∫p lo·∫°i tr·ª´ c√°c ƒë√°p √°n sai
- Gi·∫£i th√≠ch t·∫°i sao m·ªôt s·ªë ƒë√°p √°n kh√¥ng ƒë√∫ng
- V√≠ d·ª•: "Ta c√≥ $f'(x) = ...$, ƒë√°p √°n A v√† C c√≥ th·ªÉ lo·∫°i v√¨... Em th·ª≠ x√©t ti·∫øp ƒë√°p √°n c√≤n l·∫°i."
`;
      break;
      
    case 3:
      levelPrompt = `
üî¥ ƒê√ÇY L√Ä G·ª¢I √ù C·∫§P 3 (L·ªùi gi·∫£i ƒë·∫ßy ƒë·ªß):
- Gi·∫£i chi ti·∫øt t·ª´ng b∆∞·ªõc
- ƒê∆∞a ra ƒë√°p √°n ƒë√∫ng
- Gi·∫£i th√≠ch t·∫°i sao c√°c ƒë√°p √°n kh√°c sai
- T·ªïng k·∫øt ki·∫øn th·ª©c c·∫ßn nh·ªõ
- ‚ö†Ô∏è Nh·∫Øc nh·ªü h·ªçc sinh n√™n t·ª± l√†m l·∫°i b√†i t∆∞∆°ng t·ª± ƒë·ªÉ hi·ªÉu s√¢u h∆°n
`;
      break;
  }
  
  let contextPrompt = '';
  if (context) {
    contextPrompt = `
üìù TH√îNG TIN B√ÄI TO√ÅN:
- C√¢u h·ªèi: ${context.questionText || 'Kh√¥ng c√≥'}
- C√°c ƒë√°p √°n: ${context.options?.join(', ') || 'Kh√¥ng c√≥'}
- H·ªçc sinh ƒë√£ ch·ªçn: ${context.userAnswer || 'Ch∆∞a ch·ªçn'}
- ƒê√°p √°n ƒë√∫ng: ${context.correctAnswer || 'Kh√¥ng ti·∫øt l·ªô ·ªü level n√†y'}
`;
  }
  
  return basePrompt + levelPrompt + contextPrompt;
}

/**
 * Fallback response khi kh√¥ng c√≥ API ho·∫∑c l·ªói
 */
function getFallbackResponse(hintLevel: number, context?: TutorContext): TutorResponse {
  const fallbacks = [
    // Level 0
    "H√£y ƒë·ªçc k·ªπ ƒë·ªÅ b√†i v√† x√°c ƒë·ªãnh d·∫°ng to√°n tr∆∞·ªõc nh√© em! ƒê√¢y l√† b∆∞·ªõc quan tr·ªçng nh·∫•t. üìö",
    // Level 1
    "Em h√£y th·ª≠ vi·∫øt ra c√°c c√¥ng th·ª©c li√™n quan ƒë·∫øn b√†i n√†y. G·ª£i √Ω: Xem l·∫°i ph·∫ßn l√Ω thuy·∫øt v·ªÅ ch·ªß ƒë·ªÅ n√†y trong s√°ch gi√°o khoa. ‚úèÔ∏è",
    // Level 2  
    "Th·ª≠ lo·∫°i tr·ª´ c√°c ƒë√°p √°n ch·∫Øc ch·∫Øn sai tr∆∞·ªõc. Ki·ªÉm tra xem ƒë√°p √°n n√†o th·ªèa m√£n ƒëi·ªÅu ki·ªán c·ªßa ƒë·ªÅ b√†i. üîç",
    // Level 3
    "Hi·ªán t·∫°i th·∫ßy ƒëang b·∫≠n, em c√≥ th·ªÉ xem l·ªùi gi·∫£i chi ti·∫øt sau khi n·ªôp b√†i nh√©! Ho·∫∑c h·ªèi l·∫°i th·∫ßy sau. üìñ"
  ];
  
  return {
    message: fallbacks[Math.min(hintLevel, 3)],
    hintLevel,
    isFullSolution: hintLevel >= 3
  };
}

/**
 * Gi·∫£i th√≠ch ƒë√°p √°n sai sau khi quiz k·∫øt th√∫c
 */
export const explainWrongAnswer = async (
  questionText: string,
  options: string[],
  userAnswer: string,
  correctAnswer: string
): Promise<string> => {
  try {
    const prompt = `
B·∫°n l√† gia s∆∞ To√°n. H·ªçc sinh ƒë√£ tr·∫£ l·ªùi SAI m·ªôt c√¢u h·ªèi.
H√£y gi·∫£i th√≠ch ng·∫Øn g·ªçn (2-3 c√¢u) t·∫°i sao ƒë√°p √°n c·ªßa h·ªçc sinh sai v√† t·∫°i sao ƒë√°p √°n ƒë√∫ng l√† ${correctAnswer}.

C√¢u h·ªèi: ${questionText}
C√°c ƒë√°p √°n: ${options.join(', ')}
H·ªçc sinh ch·ªçn: ${userAnswer}
ƒê√°p √°n ƒë√∫ng: ${correctAnswer}

Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, s·ª≠ d·ª•ng LaTeX khi c·∫ßn (ƒë·∫∑t trong $).
`;

    const response = await ai.models.generateContent({
        model: 'gemini-3-flash-preview',
        contents: prompt,
        config: {
            temperature: 0.5,
        }
    });
    
    return response.text || `ƒê√°p √°n ƒë√∫ng l√† ${correctAnswer}. Xem l·ªùi gi·∫£i chi ti·∫øt ƒë·ªÉ hi·ªÉu r√µ h∆°n nh√©!`;
    
  } catch (error) {
    console.error('Explain error:', error);
    return `ƒê√°p √°n ƒë√∫ng l√† ${correctAnswer}. Xem l·ªùi gi·∫£i chi ti·∫øt ƒë·ªÉ hi·ªÉu r√µ h∆°n nh√©!`;
  }
};

/**
 * L·∫•y g·ª£i √Ω nhanh (1 c√¢u)
 */
export const getQuickHint = async (questionText: string): Promise<string> => {
  try {
    const prompt = `
B·∫°n l√† gia s∆∞ To√°n. Cho g·ª£i √Ω NG·∫ÆN G·ªåN (1 c√¢u) v·ªÅ c√°ch ti·∫øp c·∫≠n b√†i to√°n n√†y.
KH√îNG gi·∫£i b√†i, ch·ªâ g·ª£i √Ω h∆∞·ªõng ƒëi.

C√¢u h·ªèi: ${questionText}

Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, s·ª≠ d·ª•ng LaTeX khi c·∫ßn (ƒë·∫∑t trong $).
`;

    const response = await ai.models.generateContent({
        model: 'gemini-3-flash-preview',
        contents: prompt,
        config: {
            temperature: 0.7,
        }
    });
    
    return response.text || "H√£y x√°c ƒë·ªãnh d·∫°ng to√°n v√† c√¥ng th·ª©c c·∫ßn d√πng! üìù";
    
  } catch (error) {
    return "ƒê·ªçc k·ªπ ƒë·ªÅ v√† x√°c ƒë·ªãnh d·∫°ng to√°n tr∆∞·ªõc nh√©! üìö";
  }
};